<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Perry de Valpine, UC Berkeley" />
  <title>MCEM in Nmixture example</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="http://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script src="http://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">MCEM in Nmixture example</h1>
  <h1 class="subtitle">April 2018</h1>
  <p class="author">
Perry de Valpine, UC Berkeley
  </p>
</div>
<div id="maximum-likelihood-for-general-hierarchical-models." class="slide section level1">
<h1>Maximum likelihood for general hierarchical models.</h1>
<ul>
<li><p>A surprisingly difficult problem.</p></li>
<li><p>The likelihood to be maximized is integrated over the latent states. (Otherwise it is not really a likelihood.)</p></li>
<li><p>First, do any summation/integration over latent states by direct math or computation if possible.</p>
<ul>
<li>Example: dCHR, dDHMM, dZIP (user-defined distributions to sum over discrete latent states)</li>
</ul></li>
<li><p>Some approaches in the literature:</p>
<ul>
<li>MCEM, SAEM</li>
<li>Data cloning (Lele et al; simultaneously inveted by Jacquier et al.)</li>
<li>Laplace approximation &amp; quadrature (coming in NIMBLE, I hope).</li>
<li>More.</li>
</ul></li>
</ul>
</div>
<div id="monte-carlo-expectation-maximization" class="slide section level1">
<h1>Monte Carlo Expectation Maximization</h1>
<ul>
<li><p>Expectation Maximization (Dempster et al. 1977) is a classic algorithm for maximizing likelihood of models with random effects/latent states/missing data.</p></li>
<li><p>Classic EM only works for models with conjugacy, so the math can be done explicitly.</p></li>
<li><p>Monte Carlo EM uses Monte Carlo approximation for any hierarchical model.</p></li>
<li><p>MCEM proceeds by iterating the following steps:</p>
<ul>
<li>Hold the top-level parameters fixed and sample the latent states by MCMC (or other method).</li>
<li>Maximize the top-level parameters for the sample of latent states.</li>
</ul></li>
<li><p>Increase the MCMC sample size as the algorithm proceeds to increase accuracy for convergence.</p></li>
<li><p>The algorithm is a workhorse but can be slow!</p></li>
</ul>
</div>
<div id="example-with-the-nmixture-model" class="slide section level1">
<h1>Example with the Nmixture model</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MCEM &lt;-<span class="st"> </span><span class="kw">buildMCEM</span>(Nmix_model, <span class="kw">c</span>(<span class="st">&#39;N&#39;</span>), <span class="dt">C =</span> <span class="fl">0.02</span>)</code></pre></div>
<pre><code>## compiling... this may take a minute. Use &#39;showCompilerOutput = TRUE&#39; to see C++ compiler details.</code></pre>
<pre><code>## compilation finished.</code></pre>
<pre><code>## compiling... this may take a minute. Use &#39;showCompilerOutput = TRUE&#39; to see C++ compiler details.</code></pre>
<pre><code>## compilation finished.</code></pre>
<pre><code>## compiling... this may take a minute. Use &#39;showCompilerOutput = TRUE&#39; to see C++ compiler details.</code></pre>
<pre><code>## compilation finished.</code></pre>
<pre><code>## compiling... this may take a minute. Use &#39;showCompilerOutput = TRUE&#39; to see C++ compiler details.</code></pre>
<pre><code>## compilation finished.</code></pre>
<pre><code>## compiling... this may take a minute. Use &#39;showCompilerOutput = TRUE&#39; to see C++ compiler details.</code></pre>
<pre><code>## compilation finished.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MLEs &lt;-<span class="st"> </span>MCEM$<span class="kw">run</span>(<span class="dt">initM =</span> <span class="dv">1000</span>)</code></pre></div>
<pre><code>## |-------------|-------------|-------------|-------------|
## |-------------------------------------------------------|
## Iteration Number: 1.
## Current number of MCMC iterations: 1000.
## Parameter Estimates: 
##  alpha0[1]  alpha0[2]  alpha0[3]  alpha1[1]  alpha1[2]  alpha1[3] 
## -1.0993657 -1.5290314 -1.6457508 -3.1362048 -3.7558190 -4.4338299 
##   beta0[1]   beta0[2]   beta0[3]   beta1[1]   beta1[2]   beta1[3] 
## -2.0256069 -0.1400302 -0.7782489 -1.1441400  1.3794713  2.5368219 
## Convergence Criterion: 1.02.
## |-------------|-------------|-------------|-------------|
## |-------------------------------------------------------|
## Iteration Number: 2.
## Current number of MCMC iterations: 1000.
## Parameter Estimates: 
##  alpha0[1]  alpha0[2]  alpha0[3]  alpha1[1]  alpha1[2]  alpha1[3] 
## -1.2415240 -1.7494757 -1.9075950 -3.4611581 -4.4336969 -4.8238382 
##   beta0[1]   beta0[2]   beta0[3]   beta1[1]   beta1[2]   beta1[3] 
## -2.8029575 -0.2658124 -0.5631668 -2.0188350  1.7769682  2.4406132 
## Convergence Criterion: 1.243734.
## |-------------|-------------|-------------|-------------|
## |-------------------------------------------------------|
## Iteration Number: 3.
## Current number of MCMC iterations: 1000.
## Parameter Estimates: 
##  alpha0[1]  alpha0[2]  alpha0[3]  alpha1[1]  alpha1[2]  alpha1[3] 
## -1.2853836 -1.8080569 -1.9596226 -3.4749490 -4.5717045 -4.8407319 
##   beta0[1]   beta0[2]   beta0[3]   beta1[1]   beta1[2]   beta1[3] 
## -2.9726422 -0.2960158 -0.4412036 -2.1707298  1.9696683  2.3156169 
## Convergence Criterion: 0.1127387.
## |-------------|-------------|-------------|-------------|
## |-------------------------------------------------------|
## Iteration Number: 4.
## Current number of MCMC iterations: 1000.
## Parameter Estimates: 
##  alpha0[1]  alpha0[2]  alpha0[3]  alpha1[1]  alpha1[2]  alpha1[3] 
## -1.3011575 -1.8148213 -1.9684130 -3.4654861 -4.5594395 -4.7807834 
##   beta0[1]   beta0[2]   beta0[3]   beta1[1]   beta1[2]   beta1[3] 
## -3.1814354 -0.2986396 -0.3717864 -2.4528163  1.9428889  2.2408348 
## Convergence Criterion: 0.05063777.
## |-------------|-------------|-------------|-------------|
## |-------------------------------------------------------|
## Iteration Number: 5.
## Current number of MCMC iterations: 1000.
## Parameter Estimates: 
##  alpha0[1]  alpha0[2]  alpha0[3]  alpha1[1]  alpha1[2]  alpha1[3] 
## -1.3146393 -1.8181527 -1.9641482 -3.4349671 -4.5332485 -4.6862780 
##   beta0[1]   beta0[2]   beta0[3]   beta1[1]   beta1[2]   beta1[3] 
## -3.2420023 -0.2985505 -0.3576102 -2.5336973  2.0157084  2.2348483 
## Convergence Criterion: 0.04412921.
## |-------------|-------------|-------------|-------------|
## |-------------------------------------------------------|
## Iteration Number: 6.
## Current number of MCMC iterations: 1000.
## Parameter Estimates: 
##  alpha0[1]  alpha0[2]  alpha0[3]  alpha1[1]  alpha1[2]  alpha1[3] 
## -1.3165801 -1.8301757 -1.9879900 -3.4342490 -4.5559567 -4.7441856 
##   beta0[1]   beta0[2]   beta0[3]   beta1[1]   beta1[2]   beta1[3] 
## -3.3332380 -0.2968007 -0.3505905 -2.6174069  1.9944022  2.2288451 
## Convergence Criterion: 0.01070241.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MLEs</code></pre></div>
<pre><code>##  alpha0[1]  alpha0[2]  alpha0[3]  alpha1[1]  alpha1[2]  alpha1[3] 
## -1.3165801 -1.8301757 -1.9879900 -3.4342490 -4.5559567 -4.7441856 
##   beta0[1]   beta0[2]   beta0[3]   beta1[1]   beta1[2]   beta1[3] 
## -3.3332380 -0.2968007 -0.3505905 -2.6174069  1.9944022  2.2288451</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">save</span>(MLEs, <span class="dt">file =</span> <span class="st">&quot;Nmix_MLEs.RData&quot;</span>)</code></pre></div>
<p>The MLEs look reasonable compared to the posterior summaries.</p>
<p>They could be more accurate by decreasing C.</p>
</div>
</body>
</html>
